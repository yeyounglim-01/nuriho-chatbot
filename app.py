import streamlit as st
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import ChatMessage

# ------------------- Azure ì„¤ì • -------------------
azure_endpoint = st.secrets["AZURE_OAI_ENDPOINT"].rstrip("/")  # í˜¹ì‹œë¼ë„ ëì— / ìˆìœ¼ë©´ ì œê±°
azure_key = st.secrets["AZURE_OAI_KEY"]
llm_deployment = st.secrets["AZURE_OAI_DEPLOYMENT"]

# LLM (gpt-4o-mini)
llm = AzureChatOpenAI(
    azure_endpoint=azure_endpoint,
    api_key=azure_key,
    azure_deployment=llm_deployment,
    api_version="2024-05-01-preview",   # ì´ ë²„ì „ì´ ì œì¼ ì•ˆì •ì 
    temperature=0.3,
    max_tokens=1000
)

# Embedding (ì—¬ê¸°ì„œ ì´ë¦„ë§Œ ì •í™•íˆ ë§ì¶”ë©´ ë!)
embeddings = AzureOpenAIEmbeddings(
    azure_endpoint=azure_endpoint,
    api_key=azure_key,
    azure_deployment="ada",             # ë„ˆê°€ ë°©ê¸ˆ ë§Œë“  ì´ë¦„ì´ adaë©´ ì´ê±¸ë¡œ!
    # ë§Œì•½ ì´ë¦„ì´ ë‹¤ë¥´ë©´ ì—¬ê¸°ë§Œ ë°”ê¿” â†’ ì˜ˆ: "text-embedding-ada-002", "my-ada" ë“±
    api_version="2024-05-01-preview",   # ì´ ë²„ì „ì´ embeddingì—ì„œ ì œì¼ ì˜ ë¨
)

# ------------------- UI -------------------
st.set_page_config(page_title="ëˆ„ë¦¬í˜¸ ë°±ê³¼ì‚¬ì „", page_icon="ğŸš€")
st.title("ëˆ„ë¦¬í˜¸(KSLV-II) ë°±ê³¼ì‚¬ì „ ì±—ë´‡")

if "messages" not in st.session_state:
    st.session_state.messages = [
        ChatMessage(role="assistant", content="""
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” **ëˆ„ë¦¬í˜¸ 1ì°¨ë¶€í„° 4ì°¨ ë°œì‚¬, íƒ‘ì¬ìœ„ì„± êµì‹  ê²°ê³¼ê¹Œì§€ ì „ë¶€ ì•Œê³  ìˆëŠ” ì „ë¬¸ ì±—ë´‡**ì…ë‹ˆë‹¤!  
ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì‹œê±°ë‚˜ ì•„ë˜ ì£¼ì œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”!""")
    ]

cols = st.columns(3)
menus = [
    ("ëˆ„ë¦¬í˜¸ ëœ»ê³¼ ëª©í‘œ", "ëˆ„ë¦¬í˜¸ ì´ë¦„ì˜ ëœ»ê³¼ ê°œë°œ ëª©í‘œ ì•Œë ¤ì¤˜"),
    ("1ì°¨ ë°œì‚¬", "1ì°¨ ë°œì‚¬ ë•Œ ë¬´ìŠ¨ ì¼ ìˆì—ˆì–´?"),
    ("2ì°¨ ë°œì‚¬", "2ì°¨ ë°œì‚¬ ê³¼ì • ì„¤ëª…í•´ì¤˜"),
    ("3ì°¨ ë°œì‚¬ ì„±ê³µ", "3ì°¨ ë°œì‚¬ ì„±ê³µí–ˆì§€? ê³¼ì •ì´ ì–´ë• ì–´?"),
    ("4ì°¨ ë°œì‚¬ ì„±ê³µ", "4ì°¨ ë°œì‚¬ëŠ” ì–¸ì œ í–ˆê³  ì„±ê³µí–ˆì–´?"),
    ("4ì°¨ ìœ„ì„± êµì‹ ", "4ì°¨ ë•Œ ì˜¬ë¦° ìœ„ì„±ë“¤ êµì‹  ì˜ ë¼?")
]
for i, (label, q) in enumerate(menus):
    with cols[i % 3]:
        if st.button(label, use_container_width=True):
            st.session_state.messages.append(ChatMessage(role="user", content=q))
            st.rerun()

# ------------------- ë²¡í„°DB (í•µì‹¬ ìˆ˜ì •: ê°•ì œë¡œ ì¬ìƒì„± ë°©ì§€ + ë¡œë”© ë©”ì‹œì§€) -------------------
@st.cache_resource(show_spinner="ëˆ„ë¦¬í˜¸ ìë£Œë¥¼ ì—´ì‹¬íˆ ì½ê³  ìˆì–´ìš”... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ğŸš€")
def get_retriever():
    with st.spinner("PDFë¥¼ ì½ê³  ë²¡í„°DB ë§Œë“œëŠ” ì¤‘... (ìµœì´ˆ 1íšŒë§Œ ê±¸ë ¤ìš”!)"):
        loader = PyPDFDirectoryLoader("data/")
        docs = loader.load()
        if not docs:
            st.error("data í´ë”ì— PDF íŒŒì¼ì´ ì—†ì–´ìš”! í™•ì¸í•´ì£¼ì„¸ìš”!")
            st.stop()

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = splitter.split_documents(docs)

        vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory="./vectorstore"
        )
        return vectorstore.as_retriever(search_kwargs={"k": 6})

retriever = get_retriever()

# ------------------- RAG ì²´ì¸ -------------------
prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ëˆ„ë¦¬í˜¸ ì „ë¬¸ê°€ì•¼. ì£¼ì–´ì§„ ë¬¸ì„œë§Œ ë³´ê³  ì •í™•í•˜ê³  ë”°ëœ»í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µí•´.
ê´€ë ¨ ë¬¸ì„œ: {context}"""),
    MessagesPlaceholder("history"),
    ("human", "{question}")
])

chain = (
    {"context": retriever, "question": RunnablePassthrough(), "history": lambda x: st.session_state.messages[-10:]}
    | prompt
    | llm
    | StrOutputParser()
)

# ------------------- ì±„íŒ… -------------------
for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)

if user_input := st.chat_input("ëˆ„ë¦¬í˜¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê±° ë‹¤ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append(ChatMessage(role="user", content=user_input))
    st.chat_message("user").write(user_input)

    with st.chat_message("assistant"):
        response = chain.stream(user_input)
        answer = st.write_stream(response)
    st.session_state.messages.append(ChatMessage(role="assistant", content=answer))
