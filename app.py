import streamlit as st
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import ChatMessage
import os

# ------------------- Azure ì„¤ì • (secrets.tomlì—ì„œ ìë™ ë¡œë“œ) -------------------
azure_endpoint = st.secrets["AZURE_OAI_ENDPOINT"]
azure_key = st.secrets["AZURE_OAI_KEY"]
azure_deployment = st.secrets["AZURE_OAI_DEPLOYMENT"]

# LLM & ì„ë² ë”©
llm = AzureChatOpenAI(
    azure_endpoint=azure_endpoint,
    api_key=azure_key,
    azure_deployment=azure_deployment,
    api_version="2024-08-01-preview",
    temperature=0.3,
    max_tokens=1000
)

embeddings = AzureOpenAIEmbeddings(
    azure_endpoint=azure_endpoint,
    api_key=azure_key,
    azure_deployment=st.secrets.get("AZURE_EMBEDDING_DEPLOYMENT", "ada"),
    api_version="2024-08-01-preview"
)

# ------------------- í˜ì´ì§€ ì„¤ì • -------------------
st.set_page_config(page_title="ëˆ„ë¦¬í˜¸ ë°±ê³¼ì‚¬ì „", page_icon="ğŸš€")
st.title("ğŸš€ ëˆ„ë¦¬í˜¸(KSLV-II) ê³µì‹ê¸‰ ë°±ê³¼ì‚¬ì „ ì±—ë´‡")

if "messages" not in st.session_state:
    st.session_state.messages = [
        ChatMessage(role="assistant", content="""
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” **ëˆ„ë¦¬í˜¸ 1ì°¨ ë°œì‚¬ë¶€í„° 2025ë…„ 4ì°¨ ì™„ë²½ ì„±ê³µ, íƒ‘ì¬ìœ„ì„± êµì‹  ê²°ê³¼ê¹Œì§€ ì „ë¶€ ì•Œê³  ìˆëŠ” ëŒ€í•œë¯¼êµ­ ëŒ€í‘œ ìš°ì£¼ ì±—ë´‡**ì…ë‹ˆë‹¤!  

ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ê±°ë‚˜ ì•„ë˜ ì£¼ì œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”!
        """)
    ]

# ì˜ˆìœ ë©”ë‰´ ë²„íŠ¼ë“¤
cols = st.columns(3)
menus = [
    ("ëˆ„ë¦¬í˜¸ì˜ ëœ»ê³¼ ëª©í‘œ", "ëˆ„ë¦¬í˜¸ ì´ë¦„ ëœ»ê³¼ ê°œë°œ ëª©í‘œ ì•Œë ¤ì¤˜"),
    ("1ì°¨ ë°œì‚¬ (2021.10.21)", "1ì°¨ ë°œì‚¬ ë•Œ ë¬´ìŠ¨ ì¼ ìˆì—ˆì–´?"),
    ("2ì°¨ ë°œì‚¬ (2022.6.21)", "2ì°¨ ë°œì‚¬ ê³¼ì • ì„¤ëª…í•´ì¤˜"),
    ("3ì°¨ ë°œì‚¬ ì„±ê³µ (2023.5.25)", "3ì°¨ ë°œì‚¬ëŠ” ì„±ê³µí–ˆì§€? ê³¼ì •ì´ ì–´ë• ì–´?"),
    ("4ì°¨ ë°œì‚¬ ì„±ê³µ (2025)", "ìµœê·¼ 4ì°¨ ë°œì‚¬ëŠ” ì–¸ì œ í–ˆê³ , ì™œ ê·¸ ë‚ ì§œì˜€ì–´? ì„±ê³µí–ˆì–´?"),
    ("4ì°¨ íƒ‘ì¬ìœ„ì„± êµì‹  ê²°ê³¼", "4ì°¨ ë•Œ ìœ ìœ„ì„±ë“¤ ì§€ê¸ˆ êµì‹  ì˜ ë¼?")
]

for i, (label, q) in enumerate(menus):
    with cols[i % 3]:
        if st.button(label, use_container_width=True):
            st.session_state.messages.append(ChatMessage(role="user", content=q))
            st.rerun()

# ------------------- ë²¡í„°DB ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ ìƒì„±) -------------------
@st.cache_resource
def get_retriever():
    loader = PyPDFDirectoryLoader("data/")
    docs = loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = splitter.split_documents(docs)

    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory="./vectorstore"
    )
    return vectorstore.as_retriever(search_kwargs={"k": 6})

retriever = get_retriever()

# ------------------- RAG ì²´ì¸ -------------------
prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ëˆ„ë¦¬í˜¸(KSLV-II) ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ë¬¸ì„œë“¤ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
    1~4ì°¨ ë°œì‚¬, ë°œì‚¬ ì‹œê° ì„ ì • ì´ìœ , íƒ‘ì¬ìœ„ì„± êµì‹  ê²°ê³¼ê¹Œì§€ ì „ë¶€ ì •í™•íˆ ì•Œê³  ìˆìŠµë‹ˆë‹¤.
    ë‹µë³€ì€ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.

    ê´€ë ¨ ë¬¸ì„œ:
    {context}
    """),
    MessagesPlaceholder("history"),
    ("human", "{question}")
])

chain = (
    {"context": retriever, "question": RunnablePassthrough(), "history": lambda x: st.session_state.messages[-10:]}
    | prompt
    | llm
    | StrOutputParser()
)

# ------------------- ì±„íŒ… í‘œì‹œ & ì…ë ¥ -------------------
for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)

if prompt := st.chat_input("ëˆ„ë¦¬í˜¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê±° ë‹¤ ë¬¼ì–´ë³´ì„¸ìš”! ğŸš€"):
    st.session_state.messages.append(ChatMessage(role="user", content=prompt))
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        response = chain.stream(prompt)
        answer = st.write_stream(response)
    

    st.session_state.messages.append(ChatMessage(role="assistant", content=answer))
